{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5e50cd42-39f4-44b5-8926-40eba1f90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0c236a90-2028-47f4-8450-d2b427032267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/interim/all_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c9746b4e-d7b1-4b1d-a9a8-47fee0ecfc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
       "       'land_surface_condition', 'foundation_type', 'roof_type',\n",
       "       'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'legal_ownership_status', 'count_families', 'has_secondary_use',\n",
       "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
       "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
       "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
       "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
       "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
       "       'damage_grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "93b6e2dc-0f06-4402-ac5c-39f8e34bf7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n",
      "(260601, 39)\n",
      "(247044, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'area_percentage'].fillna(np.mean(data.loc[:, 'area_percentage'])), 95)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'area_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dce0615b-14b6-4abb-9693-594170945b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "#height_percentage\n",
    "# Function to create interaction terms\n",
    "def create_interaction_terms(X):\n",
    "    # Assuming X is a dataframe with the columns geo_level_1_id, geo_level_2_id, geo_level_3_id\n",
    "    X_new = X.copy()\n",
    "    #X_new['areaHeight'] = X_new['height_percentage'] / X_new['area_percentage']\n",
    "    X_new['geo1times2'] = X_new['geo_level_1_id'] * X_new['geo_level_2_id']\n",
    "    X_new['geo1times3'] = X_new['geo_level_1_id'] * X_new['geo_level_3_id']\n",
    "    X_new['geo2times3'] = X_new['geo_level_2_id'] * X_new['geo_level_3_id']\n",
    "    X_new['geoall'] = X_new['geo_level_2_id'] * X_new['geo_level_3_id'] * X_new['geo_level_1_id']\n",
    "    return X_new[['geo1times2', 'geo1times3', 'geo2times3', 'geoall']]#, 'areaHeight']]  # Return the interaction terms only\n",
    "\n",
    "# Creating the FunctionTransformer\n",
    "interaction_transformer = FunctionTransformer(create_interaction_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e40ef06e-9560-4fcf-84ab-4769f72f9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "      <td>247044.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.784293</td>\n",
       "      <td>705.920686</td>\n",
       "      <td>6263.536168</td>\n",
       "      <td>2.122193</td>\n",
       "      <td>26.682757</td>\n",
       "      <td>7.308403</td>\n",
       "      <td>5.380519</td>\n",
       "      <td>0.088102</td>\n",
       "      <td>0.782917</td>\n",
       "      <td>0.034581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027894</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>2.254121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.968545</td>\n",
       "      <td>410.536461</td>\n",
       "      <td>3642.368254</td>\n",
       "      <td>0.711754</td>\n",
       "      <td>73.527319</td>\n",
       "      <td>2.774035</td>\n",
       "      <td>1.842914</td>\n",
       "      <td>0.283443</td>\n",
       "      <td>0.412260</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164669</td>\n",
       "      <td>0.076987</td>\n",
       "      <td>0.024303</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.030564</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.070783</td>\n",
       "      <td>0.603290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>3086.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>6277.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>9414.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "count   247044.000000   247044.000000   247044.000000        247044.000000   \n",
       "mean        13.784293      705.920686     6263.536168             2.122193   \n",
       "std          7.968545      410.536461     3642.368254             0.711754   \n",
       "min          0.000000        0.000000        0.000000             1.000000   \n",
       "25%          7.000000      356.000000     3086.750000             2.000000   \n",
       "50%         12.000000      710.000000     6277.000000             2.000000   \n",
       "75%         21.000000     1051.000000     9414.000000             2.000000   \n",
       "max         30.000000     1427.000000    12567.000000             9.000000   \n",
       "\n",
       "                 age  area_percentage  height_percentage  \\\n",
       "count  247044.000000    247044.000000      247044.000000   \n",
       "mean       26.682757         7.308403           5.380519   \n",
       "std        73.527319         2.774035           1.842914   \n",
       "min         0.000000         1.000000           2.000000   \n",
       "25%        10.000000         5.000000           4.000000   \n",
       "50%        15.000000         7.000000           5.000000   \n",
       "75%        30.000000         9.000000           6.000000   \n",
       "max       995.000000        15.000000          32.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "count                 247044.000000                        247044.000000   \n",
       "mean                       0.088102                             0.782917   \n",
       "std                        0.283443                             0.412260   \n",
       "min                        0.000000                             0.000000   \n",
       "25%                        0.000000                             1.000000   \n",
       "50%                        0.000000                             1.000000   \n",
       "75%                        0.000000                             1.000000   \n",
       "max                        1.000000                             1.000000   \n",
       "\n",
       "       has_superstructure_stone_flag  ...  has_secondary_use_hotel  \\\n",
       "count                  247044.000000  ...            247044.000000   \n",
       "mean                        0.034581  ...                 0.027894   \n",
       "std                         0.182716  ...                 0.164669   \n",
       "min                         0.000000  ...                 0.000000   \n",
       "25%                         0.000000  ...                 0.000000   \n",
       "50%                         0.000000  ...                 0.000000   \n",
       "75%                         0.000000  ...                 0.000000   \n",
       "max                         1.000000  ...                 1.000000   \n",
       "\n",
       "       has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "count             247044.000000                  247044.000000   \n",
       "mean                   0.005963                       0.000591   \n",
       "std                    0.076987                       0.024303   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       has_secondary_use_school  has_secondary_use_industry  \\\n",
       "count             247044.000000               247044.000000   \n",
       "mean                   0.000202                    0.000935   \n",
       "std                    0.014225                    0.030564   \n",
       "min                    0.000000                    0.000000   \n",
       "25%                    0.000000                    0.000000   \n",
       "50%                    0.000000                    0.000000   \n",
       "75%                    0.000000                    0.000000   \n",
       "max                    1.000000                    1.000000   \n",
       "\n",
       "       has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "count                  247044.000000                 247044.000000   \n",
       "mean                        0.000146                      0.000113   \n",
       "std                         0.012071                      0.010646   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                         0.000000                      0.000000   \n",
       "50%                         0.000000                      0.000000   \n",
       "75%                         0.000000                      0.000000   \n",
       "max                         1.000000                      1.000000   \n",
       "\n",
       "       has_secondary_use_use_police  has_secondary_use_other   damage_grade  \n",
       "count                 247044.000000            247044.000000  247044.000000  \n",
       "mean                       0.000085                 0.005036       2.254121  \n",
       "std                        0.009219                 0.070783       0.603290  \n",
       "min                        0.000000                 0.000000       1.000000  \n",
       "25%                        0.000000                 0.000000       2.000000  \n",
       "50%                        0.000000                 0.000000       2.000000  \n",
       "75%                        0.000000                 0.000000       3.000000  \n",
       "max                        1.000000                 1.000000       3.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = data.select_dtypes(exclude=['object'])\n",
    "numerical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f3567d6b-eff7-4861-ba8f-f1615942fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "def get_right_skewed_columns(df, skew_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns the names of columns that are right-skewed based on the skewness value, excluding binary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The input DataFrame (numerical columns only).\n",
    "    - skew_threshold: The skewness threshold above which a column is considered right-skewed (default is 0.5).\n",
    "    \n",
    "    Returns:\n",
    "    - List of column names that are right-skewed.\n",
    "    \"\"\"\n",
    "    right_skewed_columns = []\n",
    "    \n",
    "    # Iterate through each column in the dataframe\n",
    "    for col in df.columns:\n",
    "        # Check if the column has more than 2 unique values (to avoid binary columns)\n",
    "        if df[col].nunique() > 2:\n",
    "            # Calculate skewness for each column\n",
    "            col_skewness = skew(df[col].dropna())  # Drop NaN values to avoid issues\n",
    "            \n",
    "            # Check if the skewness is above the specified threshold (indicating right-skewness)\n",
    "            if col_skewness > skew_threshold:\n",
    "                right_skewed_columns.append(col)\n",
    "    \n",
    "    return right_skewed_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d0f2e52e-cd8a-4bef-b7ee-8203b14255a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-skewed columns: ['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage', 'count_families']\n"
     ]
    }
   ],
   "source": [
    "# # Select numerical columns\n",
    "# numerical_df = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# # Get the right-skewed columns\n",
    "right_skewed_cols = get_right_skewed_columns(numerical_df)\n",
    "\n",
    "print(\"Right-skewed columns:\", right_skewed_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "0b91e41a-e47d-4d42-a792-9c23b1484604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def apply_log_transformation(df, columns):\n",
    "#     \"\"\"\n",
    "#     Applies log transformation to the specified columns of the DataFrame.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: The input DataFrame.\n",
    "#     - columns: List of column names to apply the log transformation on.\n",
    "    \n",
    "#     Returns:\n",
    "#     - DataFrame with log-transformed columns.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     df_transformed = df.copy()\n",
    "    \n",
    "#     # Apply log transformation to each specified column\n",
    "#     for col in columns:\n",
    "#         # Add a small constant to avoid log(0) and handle any zeros or negatives\n",
    "#         df_transformed[col] = np.log1p([col])\n",
    "    \n",
    "#     return df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "80619d75-f6d4-4a9a-9b85-4ae1bea084b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the right-skewed columns (excluding binary columns)\n",
    "#right_skewed_cols = get_right_skewed_columns(numerical_df)\n",
    "#numerical_df = apply_log_transformation(numerical_df, right_skewed_cols)\n",
    "#data[right_skewed_cols] = numerical_df[right_skewed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "70b59429-e3a5-4659-a690-451343d1a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pct = np.percentile(data.loc[:, 'age'].fillna(np.mean(data.loc[:, 'age'])), 99)\n",
    "#print(pct)\n",
    "#print(data.shape)\n",
    "#data = data.loc[data.loc[:, 'age'] < pct]\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a3911ffc-6f59-459a-919b-a0331862a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(X):\n",
    "    # Apply log1p transformation (log(1 + x)) to avoid issues with zero values\n",
    "    return np.log1p(X)\n",
    "\n",
    "# Create a FunctionTransformer for log transformation\n",
    "log_transformer = FunctionTransformer(log_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "58e3fc36-e7c3-4402-94f1-e6ff2ca0a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Custom transformer for the age-based transformation\n",
    "class AgeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, age_column='age'):\n",
    "        self.age_column = age_column\n",
    "        self.percentile_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate the 99th percentile of the 'age' column and store it\n",
    "        self.percentile_ = np.percentile(X[self.age_column].fillna(np.mean(X[self.age_column])), 99)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Add a new 'old' column to indicate if the age exceeds the 99th percentile\n",
    "        X_copy['old'] = np.where(X_copy[self.age_column] >= self.percentile_, 1, 0)\n",
    "        \n",
    "        # Cap the age to 100 where the 'old' column is 1\n",
    "        X_copy.loc[X_copy['old'] == 1, self.age_column] = 100\n",
    "        \n",
    "        return X_copy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "00a9abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class geoTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, min):\n",
    "        self.cols = cols\n",
    "        self.min = min\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.value_counts_ = {}\n",
    "        for col in self.cols:\n",
    "            self.value_counts_[col] = X[col].value_counts()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.cols:\n",
    "            counts = self.value_counts_[col]\n",
    "            mask = X[col].map(counts) < self.min\n",
    "            X_transformed.loc[mask, col] = -1\n",
    "        return X_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8ade25df-1961-4cd1-8288-7d019804fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['damage_grade'])\n",
    "y = data.damage_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b8cd2381-4b97-4e93-b311-2de1edc0cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({1: 0, 2: 1, 3: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "dba1291f-ff62-40e5-944a-6372b3517406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         2\n",
       "3         1\n",
       "4         2\n",
       "         ..\n",
       "260596    1\n",
       "260597    2\n",
       "260598    2\n",
       "260599    1\n",
       "260600    2\n",
       "Name: damage_grade, Length: 247044, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f1c9c93a-0124-4e52-8c6f-1f0d62805c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    141177\n",
       "2     84323\n",
       "0     21544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f62d6401-05c2-4de0-86e9-9a012300ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.old.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0243ff84-fb14-4ecb-a5cf-953277152a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_df = data.select_dtypes(exclude=['object'])\n",
    "#categorical_df = data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ca1d5990-7836-4ff9-9cdf-689ddc2445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in x.columns if  x[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int32', 'int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "83ebf2c7-490c-43b9-811f-3c2d149b9f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['land_surface_condition',\n",
       " 'foundation_type',\n",
       " 'roof_type',\n",
       " 'ground_floor_type',\n",
       " 'other_floor_type',\n",
       " 'position',\n",
       " 'plan_configuration',\n",
       " 'legal_ownership_status']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1b4ea3f2-1ccf-462f-b581-c21426c40fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(numerical_df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "712173a0-97d3-4475-b68f-a303af290e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler, MinMaxScaler\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "5390eb12-6721-40bc-a3e9-f60d922a8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    98897\n",
       "2    58949\n",
       "0    15084\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "aca1c3dc-856a-47b7-8258-2657b4318b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    42280\n",
       "2    25374\n",
       "0     6460\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ca8125c8-9a46-4a44-b21d-d48ce2f8478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BaseNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "dddedeba-4ffe-4e0e-a8b8-ce15fe7864a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.eda_first import summarize_dataframe\n",
    "#summarize_dataframe(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ffc2a3a0-b3d2-49f0-90c6-4474abe506e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numerical transformer\n",
    "\n",
    "numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "#create categorical transformer\n",
    "#categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "#                                            ])\n",
    "\n",
    "base_encoder_columns = ['land_surface_condition','geo_level_1_id', 'geo_level_2_id','geo_level_3_id',\n",
    " 'foundation_type',\n",
    " 'roof_type',\n",
    " 'ground_floor_type',\n",
    " 'other_floor_type',\n",
    " 'position',\n",
    " 'plan_configuration',\n",
    " 'legal_ownership_status']\n",
    "\n",
    "base_encoder = Pipeline(steps=[\n",
    "    ('base_encoder', BaseNEncoder(cols=base_encoder_columns, base=3))\n",
    "])\n",
    "geo_columns = ['geo_level_1_id', 'geo_level_2_id','geo_level_3_id']\n",
    "geo_encoder = Pipeline(steps=[\n",
    "    ('geo_encoder', geoTransformer(cols=geo_columns, min=5))\n",
    "])\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    ('age_transform', AgeTransformer(age_column='age'))  # Apply age transformation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "69e4328c-afab-40e1-a982-c79bb93326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the transformations using ColumnTransformer\n",
    "#preprocessor = ColumnTransformer(transformers=[\n",
    "#    ('base_name', base_encoder, base_encoder_columns)])  # TargetEncoder for 'town'\n",
    "#    ('num', numerical_transformer, numerical_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ee3cdd35-41ef-4fc8-ab5f-3a6a69cf8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated ColumnTransformer with the log transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    #('geo_encoder', geo_encoder, geo_columns),\n",
    "    ('base_name', base_encoder, base_encoder_columns),  # BaseNEncoder for categorical columns\n",
    "    ('age_transform', age_transformer, ['age']),  # Custom transformer for the 'age' column\n",
    "    ('num', 'passthrough', numerical_cols),  # Pass numerical columns through without transformation\n",
    "    ('interaction', interaction_transformer, ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'height_percentage', 'area_percentage']),  # Interaction terms\n",
    "    ('log_transform', log_transformer, right_skewed_cols)  # Apply log transformation to specified columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "17c7ee6b-4d40-4c75-8673-fb68368f83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.7457295517715951\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.49      0.57      6460\n",
      "           1       0.75      0.85      0.79     42280\n",
      "           2       0.76      0.64      0.70     25374\n",
      "\n",
      "    accuracy                           0.75     74114\n",
      "   macro avg       0.73      0.66      0.69     74114\n",
      "weighted avg       0.74      0.75      0.74     74114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.2669112505018992,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    reg_lambda=1.2259716591605452,\n",
    "    subsample=0.704976942819638,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=4,\n",
    "    alpha= 0.14170716330946964,    # Added L1 regularization\n",
    "    eval_metric='mlogloss',  # Consider custom loss for ordinal\n",
    "    objective='multi:softmax',  # Using softmax but can tweak for ordinal\n",
    "    num_class=3  # Assuming 3 ordinal classes\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "    ('xgboost', xgb)  # Step 3: Model training\n",
    "])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "#rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of training data, fit model after upsampling!\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d64ed6c4-ad09-4587-9fd8-6430598e11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.7980743653501416\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71     15084\n",
      "           1       0.79      0.89      0.84     98897\n",
      "           2       0.81      0.69      0.75     58949\n",
      "\n",
      "    accuracy                           0.80    172930\n",
      "   macro avg       0.80      0.74      0.76    172930\n",
      "weighted avg       0.80      0.80      0.79    172930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_train, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "daeb6fd1-1fb3-4479-8978-2a38fc3f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/raw/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "dafbc507-fb2c-4ad2-8134-70d35d158954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = test_data.building_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "730a579f-3081-41a2-85ae-7ebc758060d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         300051\n",
       "1          99355\n",
       "2         890251\n",
       "3         745817\n",
       "4         421793\n",
       "          ...   \n",
       "86863     310028\n",
       "86864     663567\n",
       "86865    1049160\n",
       "86866     442785\n",
       "86867     501372\n",
       "Name: building_id, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b8315b74-c8b7-46a7-8bf9-e92323217a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        2\n",
       "        ..\n",
       "86863    1\n",
       "86864    2\n",
       "86865    1\n",
       "86866    1\n",
       "86867    0\n",
       "Length: 86868, dtype: int32"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_preds = rf_pipe.predict(test_data)\n",
    "rf_preds = pd.Series(rf_preds)\n",
    "rf_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "80bebbfa-d40f-41b9-9103-a3dfca239303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([X_test_final, rf_preds], axis=1)\n",
    "df_concatenated\n",
    "df_concatenated = df_concatenated.rename(columns={0: 'damage_grade'})\n",
    "df_concatenated\n",
    "df_concatenated['damage_grade'] = df_concatenated['damage_grade'].replace({0: 1, 1: 2, 2: 3})\n",
    "df_concatenated.to_csv('../data/processed/ATsubmission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28226e9-3c26-44cb-beda-9c50233aadc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
