{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e50cd42-39f4-44b5-8926-40eba1f90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c236a90-2028-47f4-8450-d2b427032267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/interim/all_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9746b4e-d7b1-4b1d-a9a8-47fee0ecfc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
       "       'land_surface_condition', 'foundation_type', 'roof_type',\n",
       "       'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'legal_ownership_status', 'count_families', 'has_secondary_use',\n",
       "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
       "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
       "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
       "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
       "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
       "       'damage_grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93b6e2dc-0f06-4402-ac5c-39f8e34bf7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "(260601, 39)\n",
      "(252139, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'area_percentage'].fillna(np.mean(data.loc[:, 'area_percentage'])), 97)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'area_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de14c99b-b13c-4ee8-8655-3adbd46bd28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "(252139, 39)\n",
      "(240799, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'height_percentage'].fillna(np.mean(data.loc[:, 'height_percentage'])), 97)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'height_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce0615b-14b6-4abb-9693-594170945b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class GeoInteractionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to create geo interaction terms by concatenating the geo-level IDs.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_new = X.copy()\n",
    "        # Concatenate geo_level_1_id, geo_level_2_id, and geo_level_3_id\n",
    "        X_new['geo1_geo2'] = X_new['geo_level_1_id'].astype(str) + '_' + X_new['geo_level_2_id'].astype(str)\n",
    "        X_new['geo1_geo3'] = X_new['geo_level_1_id'].astype(str) + '_' + X_new['geo_level_3_id'].astype(str)\n",
    "        X_new['geo2_geo3'] = X_new['geo_level_2_id'].astype(str) + '_' + X_new['geo_level_3_id'].astype(str)\n",
    "        X_new['geo_all'] = (\n",
    "            X_new['geo_level_1_id'].astype(str) + '_' + \n",
    "            X_new['geo_level_2_id'].astype(str) + '_' +\n",
    "            X_new['geo_level_3_id'].astype(str)\n",
    "        )\n",
    "        # Return the entire dataframe including original and new columns\n",
    "        return X_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e40ef06e-9560-4fcf-84ab-4769f72f9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.853758</td>\n",
       "      <td>702.139207</td>\n",
       "      <td>6276.924360</td>\n",
       "      <td>2.053489</td>\n",
       "      <td>25.865037</td>\n",
       "      <td>7.418868</td>\n",
       "      <td>5.160956</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.797292</td>\n",
       "      <td>0.035121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>2.254665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.938389</td>\n",
       "      <td>409.412468</td>\n",
       "      <td>3646.519437</td>\n",
       "      <td>0.624599</td>\n",
       "      <td>72.641948</td>\n",
       "      <td>2.973722</td>\n",
       "      <td>1.460206</td>\n",
       "      <td>0.272946</td>\n",
       "      <td>0.402018</td>\n",
       "      <td>0.184085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154525</td>\n",
       "      <td>0.071057</td>\n",
       "      <td>0.023318</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.030621</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.603874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>3098.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>6289.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>9440.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "count   240799.000000   240799.000000   240799.000000        240799.000000   \n",
       "mean        13.853758      702.139207     6276.924360             2.053489   \n",
       "std          7.938389      409.412468     3646.519437             0.624599   \n",
       "min          0.000000        0.000000        0.000000             1.000000   \n",
       "25%          7.000000      355.000000     3098.500000             2.000000   \n",
       "50%         12.000000      706.000000     6289.000000             2.000000   \n",
       "75%         21.000000     1050.000000     9440.000000             2.000000   \n",
       "max         30.000000     1427.000000    12567.000000             9.000000   \n",
       "\n",
       "                 age  area_percentage  height_percentage  \\\n",
       "count  240799.000000    240799.000000      240799.000000   \n",
       "mean       25.865037         7.418868           5.160956   \n",
       "std        72.641948         2.973722           1.460206   \n",
       "min         0.000000         1.000000           2.000000   \n",
       "25%        10.000000         5.000000           4.000000   \n",
       "50%        15.000000         7.000000           5.000000   \n",
       "75%        30.000000         9.000000           6.000000   \n",
       "max       995.000000        17.000000           8.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "count                 240799.000000                        240799.000000   \n",
       "mean                       0.081072                             0.797292   \n",
       "std                        0.272946                             0.402018   \n",
       "min                        0.000000                             0.000000   \n",
       "25%                        0.000000                             1.000000   \n",
       "50%                        0.000000                             1.000000   \n",
       "75%                        0.000000                             1.000000   \n",
       "max                        1.000000                             1.000000   \n",
       "\n",
       "       has_superstructure_stone_flag  ...  has_secondary_use_hotel  \\\n",
       "count                  240799.000000  ...            240799.000000   \n",
       "mean                        0.035121  ...                 0.024477   \n",
       "std                         0.184085  ...                 0.154525   \n",
       "min                         0.000000  ...                 0.000000   \n",
       "25%                         0.000000  ...                 0.000000   \n",
       "50%                         0.000000  ...                 0.000000   \n",
       "75%                         0.000000  ...                 0.000000   \n",
       "max                         1.000000  ...                 1.000000   \n",
       "\n",
       "       has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "count             240799.000000                  240799.000000   \n",
       "mean                   0.005075                       0.000544   \n",
       "std                    0.071057                       0.023318   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       has_secondary_use_school  has_secondary_use_industry  \\\n",
       "count             240799.000000               240799.000000   \n",
       "mean                   0.000174                    0.000939   \n",
       "std                    0.013206                    0.030621   \n",
       "min                    0.000000                    0.000000   \n",
       "25%                    0.000000                    0.000000   \n",
       "50%                    0.000000                    0.000000   \n",
       "75%                    0.000000                    0.000000   \n",
       "max                    1.000000                    1.000000   \n",
       "\n",
       "       has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "count                  240799.000000                 240799.000000   \n",
       "mean                        0.000133                      0.000087   \n",
       "std                         0.011527                      0.009338   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                         0.000000                      0.000000   \n",
       "50%                         0.000000                      0.000000   \n",
       "75%                         0.000000                      0.000000   \n",
       "max                         1.000000                      1.000000   \n",
       "\n",
       "       has_secondary_use_use_police  has_secondary_use_other   damage_grade  \n",
       "count                 240799.000000            240799.000000  240799.000000  \n",
       "mean                       0.000083                 0.004842       2.254665  \n",
       "std                        0.009113                 0.069417       0.603874  \n",
       "min                        0.000000                 0.000000       1.000000  \n",
       "25%                        0.000000                 0.000000       2.000000  \n",
       "50%                        0.000000                 0.000000       2.000000  \n",
       "75%                        0.000000                 0.000000       3.000000  \n",
       "max                        1.000000                 1.000000       3.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = data.select_dtypes(exclude=['object'])\n",
    "numerical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3567d6b-eff7-4861-ba8f-f1615942fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "def get_right_skewed_columns(df, skew_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns the names of columns that are right-skewed based on the skewness value, excluding binary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The input DataFrame (numerical columns only).\n",
    "    - skew_threshold: The skewness threshold above which a column is considered right-skewed (default is 0.5).\n",
    "    \n",
    "    Returns:\n",
    "    - List of column names that are right-skewed.\n",
    "    \"\"\"\n",
    "    right_skewed_columns = []\n",
    "    \n",
    "    # Iterate through each column in the dataframe\n",
    "    for col in df.columns:\n",
    "        # Check if the column has more than 2 unique values (to avoid binary columns)\n",
    "        if df[col].nunique() > 2:\n",
    "            # Calculate skewness for each column\n",
    "            col_skewness = skew(df[col].dropna())  # Drop NaN values to avoid issues\n",
    "            \n",
    "            # Check if the skewness is above the specified threshold (indicating right-skewness)\n",
    "            if col_skewness > skew_threshold:\n",
    "                right_skewed_columns.append(col)\n",
    "    \n",
    "    return right_skewed_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0f2e52e-cd8a-4bef-b7ee-8203b14255a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-skewed columns: ['age', 'area_percentage', 'count_families']\n"
     ]
    }
   ],
   "source": [
    "# # Select numerical columns\n",
    "# numerical_df = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# # Get the right-skewed columns\n",
    "right_skewed_cols = get_right_skewed_columns(numerical_df)\n",
    "\n",
    "print(\"Right-skewed columns:\", right_skewed_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3911ffc-6f59-459a-919b-a0331862a43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58e3fc36-e7c3-4402-94f1-e6ff2ca0a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Custom transformer for the age-based transformation\n",
    "class AgeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, age_column='age'):\n",
    "        self.age_column = age_column\n",
    "        self.percentile_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate the 99th percentile of the 'age' column and store it\n",
    "        self.percentile_ = np.percentile(X[self.age_column].fillna(np.mean(X[self.age_column])), 99)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Add a new 'old' column to indicate if the age exceeds the 99th percentile\n",
    "        X_copy['old'] = np.where(X_copy[self.age_column] >= self.percentile_, 1, 0)\n",
    "        \n",
    "        # Cap the age to 100 where the 'old' column is 1\n",
    "        X_copy.loc[X_copy['old'] == 1, self.age_column] = 100\n",
    "        \n",
    "        return X_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ade25df-1961-4cd1-8288-7d019804fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['damage_grade'])\n",
    "y = data.damage_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8cd2381-4b97-4e93-b311-2de1edc0cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({1: 0, 2: 1, 3: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dba1291f-ff62-40e5-944a-6372b3517406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         2\n",
       "3         1\n",
       "5         1\n",
       "         ..\n",
       "260596    1\n",
       "260597    2\n",
       "260598    2\n",
       "260599    1\n",
       "260600    2\n",
       "Name: damage_grade, Length: 240799, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1c9c93a-0124-4e52-8c6f-1f0d62805c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    137372\n",
       "2     82375\n",
       "0     21052\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f62d6401-05c2-4de0-86e9-9a012300ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.old.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0243ff84-fb14-4ecb-a5cf-953277152a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_df = data.select_dtypes(exclude=['object'])\n",
    "#categorical_df = data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca1d5990-7836-4ff9-9cdf-689ddc2445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in x.columns if  x[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int32', 'int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83ebf2c7-490c-43b9-811f-3c2d149b9f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['land_surface_condition',\n",
       " 'foundation_type',\n",
       " 'roof_type',\n",
       " 'ground_floor_type',\n",
       " 'other_floor_type',\n",
       " 'position',\n",
       " 'plan_configuration',\n",
       " 'legal_ownership_status']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b4ea3f2-1ccf-462f-b581-c21426c40fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(numerical_df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "712173a0-97d3-4475-b68f-a303af290e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler, MinMaxScaler\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5390eb12-6721-40bc-a3e9-f60d922a8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    96394\n",
       "2    57400\n",
       "0    14765\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aca1c3dc-856a-47b7-8258-2657b4318b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    40978\n",
       "2    24975\n",
       "0     6287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca8125c8-9a46-4a44-b21d-d48ce2f8478d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcategory_encoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseNEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "from category_encoders import BaseNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dddedeba-4ffe-4e0e-a8b8-ce15fe7864a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Using cached category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from category_encoders) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from category_encoders) (0.14.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from category_encoders) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rapha\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n",
      "Using cached category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n",
      "Installing collected packages: category_encoders\n",
      "Successfully installed category_encoders-2.6.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffc2a3a0-b3d2-49f0-90c6-4474abe506e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numerical transformer\n",
    "\n",
    "numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "#create categorical transformer\n",
    "#categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "#                                            ])\n",
    "\n",
    "base_encoder_columns = ['land_surface_condition', 'geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
    " 'foundation_type',\n",
    " 'roof_type',\n",
    " 'ground_floor_type',\n",
    " 'other_floor_type',\n",
    " 'position',\n",
    " 'plan_configuration',\n",
    " 'legal_ownership_status']\n",
    "\n",
    "base_encoder = Pipeline(steps=[\n",
    "    ('base_encoder', BaseNEncoder(cols=base_encoder_columns, base=5))\n",
    "])\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    ('age_transform', AgeTransformer(age_column='age'))  # Apply age transformation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "69e4328c-afab-40e1-a982-c79bb93326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the transformations using ColumnTransformer\n",
    "#preprocessor = ColumnTransformer(transformers=[\n",
    "#    ('base_name', base_encoder, base_encoder_columns)])  # TargetEncoder for 'town'\n",
    "#    ('num', numerical_transformer, numerical_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee3cdd35-41ef-4fc8-ab5f-3a6a69cf8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated ColumnTransformer with the log transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('base_name', base_encoder, base_encoder_columns),  # BaseNEncoder for categorical columns\n",
    "    ('age_transform', age_transformer, ['age']),  # Custom transformer for the 'age' column\n",
    "    ('num', 'passthrough', numerical_cols),  # Pass numerical columns through without transformation\n",
    "    ('interaction', interaction_transformer, ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'height_percentage', 'area_percentage']),  # Interaction terms\n",
    "    ('log_transform', log_transformer, right_skewed_cols)  # Apply log transformation to specified columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3af85d6-3871-4f19-a54c-1daf5d2a8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# # LightGBM for Multiclass Classification\n",
    "# lgbm = LGBMClassifier(\n",
    "#     n_estimators=800,\n",
    "#     learning_rate=0.2669112505018992,\n",
    "#     max_depth=5,\n",
    "#     random_state=42,\n",
    "#     reg_lambda=1.2259716591605452,  # L2 regularization\n",
    "#     subsample=0.704976942819638,    # Subsample ratio of the training instances\n",
    "#     colsample_bytree=0.9,           # Subsample ratio of columns when constructing each tree\n",
    "#     min_child_weight=4,             # Equivalent of min_data_in_leaf in LightGBM\n",
    "#     reg_alpha=0.14170716330946964,  # L1 regularization term\n",
    "#     objective='multiclass',         # Objective for multiclass classification\n",
    "#     metric='multi_logloss',         # Metric used for multiclass classification\n",
    "#     num_class=3                     # Specify the number of classes in the target\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# rf_pipe = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "#     ('xgboost', lgbm)  # Step 3: Model training\n",
    "# ])\n",
    "\n",
    "# # Preprocessing of training data, fit model \n",
    "# #rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Preprocessing of training data, fit model after upsampling!\n",
    "# rf_pipe.fit(x, y)\n",
    "\n",
    "# # Preprocessing of validation data, get predictions\n",
    "# #rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# #accuracy = accuracy_score(y_test, rf_preds)\n",
    "# #print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# # Detailed classification report\n",
    "# #print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17c7ee6b-4d40-4c75-8673-fb68368f83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.7431112308832446\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58      6775\n",
      "           1       0.74      0.84      0.79     42102\n",
      "           2       0.76      0.64      0.69     25338\n",
      "\n",
      "    accuracy                           0.74     74215\n",
      "   macro avg       0.72      0.66      0.69     74215\n",
      "weighted avg       0.74      0.74      0.74     74215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.2669112505018992,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    reg_lambda=1.2259716591605452,\n",
    "    subsample=0.704976942819638,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=4,\n",
    "    alpha= 0.14170716330946964,    # Added L1 regularization\n",
    "    eval_metric='mlogloss',  # Consider custom loss for ordinal\n",
    "    objective='multi:softmax',  # Using softmax but can tweak for ordinal\n",
    "    num_class=3  # Assuming 3 ordinal classes\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "    ('xgboost', xgb)  # Step 3: Model training\n",
    "])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "#rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of training data, fit model after upsampling!\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d64ed6c4-ad09-4587-9fd8-6430598e11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.799130319287162\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.71     15889\n",
      "           1       0.79      0.89      0.84     98747\n",
      "           2       0.81      0.70      0.75     58531\n",
      "\n",
      "    accuracy                           0.80    173167\n",
      "   macro avg       0.80      0.74      0.77    173167\n",
      "weighted avg       0.80      0.80      0.80    173167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_train, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "daeb6fd1-1fb3-4479-8978-2a38fc3f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/raw/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dafbc507-fb2c-4ad2-8134-70d35d158954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = test_data.building_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "730a579f-3081-41a2-85ae-7ebc758060d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         300051\n",
       "1          99355\n",
       "2         890251\n",
       "3         745817\n",
       "4         421793\n",
       "          ...   \n",
       "86863     310028\n",
       "86864     663567\n",
       "86865    1049160\n",
       "86866     442785\n",
       "86867     501372\n",
       "Name: building_id, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b8315b74-c8b7-46a7-8bf9-e92323217a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        2\n",
       "        ..\n",
       "86863    1\n",
       "86864    1\n",
       "86865    1\n",
       "86866    1\n",
       "86867    1\n",
       "Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_preds = rf_pipe.predict(test_data)\n",
    "rf_preds = pd.Series(rf_preds)\n",
    "rf_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "80bebbfa-d40f-41b9-9103-a3dfca239303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([X_test_final, rf_preds], axis=1)\n",
    "df_concatenated\n",
    "df_concatenated = df_concatenated.rename(columns={0: 'damage_grade'})\n",
    "df_concatenated\n",
    "df_concatenated['damage_grade'] = df_concatenated['damage_grade'].replace({0: 1, 1: 2, 2: 3})\n",
    "df_concatenated.to_csv('../data/processed/submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28226e9-3c26-44cb-beda-9c50233aadc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
