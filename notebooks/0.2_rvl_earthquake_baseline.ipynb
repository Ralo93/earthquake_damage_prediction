{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e50cd42-39f4-44b5-8926-40eba1f90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c236a90-2028-47f4-8450-d2b427032267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/interim/all_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9746b4e-d7b1-4b1d-a9a8-47fee0ecfc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
       "       'land_surface_condition', 'foundation_type', 'roof_type',\n",
       "       'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'legal_ownership_status', 'count_families', 'has_secondary_use',\n",
       "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
       "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
       "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
       "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
       "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
       "       'damage_grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93b6e2dc-0f06-4402-ac5c-39f8e34bf7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0\n",
      "(247382, 39)\n",
      "(238708, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'area_percentage'].fillna(np.mean(data.loc[:, 'area_percentage'])), 97)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'area_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de14c99b-b13c-4ee8-8655-3adbd46bd28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "(238708, 39)\n",
      "(225574, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'height_percentage'].fillna(np.mean(data.loc[:, 'height_percentage'])), 97)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'height_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce0615b-14b6-4abb-9693-594170945b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class GeoInteractionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to create geo interaction terms by concatenating the geo-level IDs.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_new = X.copy()\n",
    "        # Concatenate geo_level_1_id, geo_level_2_id, and geo_level_3_id\n",
    "        X_new['geo1_geo2'] = X_new['geo_level_1_id'].astype(str) + '_' + X_new['geo_level_2_id'].astype(str)\n",
    "        X_new['geo1_geo3'] = X_new['geo_level_1_id'].astype(str) + '_' + X_new['geo_level_3_id'].astype(str)\n",
    "        X_new['geo2_geo3'] = X_new['geo_level_2_id'].astype(str) + '_' + X_new['geo_level_3_id'].astype(str)\n",
    "        X_new['geo_all'] = (\n",
    "            X_new['geo_level_1_id'].astype(str) + '_' + \n",
    "            X_new['geo_level_2_id'].astype(str) + '_' +\n",
    "            X_new['geo_level_3_id'].astype(str)\n",
    "        )\n",
    "        # Return the entire dataframe including original and new columns\n",
    "        return X_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40ef06e-9560-4fcf-84ab-4769f72f9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "      <td>247382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.925641</td>\n",
       "      <td>699.396824</td>\n",
       "      <td>6274.675999</td>\n",
       "      <td>2.050921</td>\n",
       "      <td>25.789831</td>\n",
       "      <td>7.842487</td>\n",
       "      <td>5.167842</td>\n",
       "      <td>0.081586</td>\n",
       "      <td>0.787098</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026877</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>2.247411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.975966</td>\n",
       "      <td>410.537497</td>\n",
       "      <td>3649.828439</td>\n",
       "      <td>0.626674</td>\n",
       "      <td>72.616479</td>\n",
       "      <td>4.104327</td>\n",
       "      <td>1.466223</td>\n",
       "      <td>0.273734</td>\n",
       "      <td>0.409359</td>\n",
       "      <td>0.183971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161726</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>0.026128</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>0.607808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>3094.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>6287.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "      <td>9440.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "count   247382.000000   247382.000000   247382.000000        247382.000000   \n",
       "mean        13.925641      699.396824     6274.675999             2.050921   \n",
       "std          7.975966      410.537497     3649.828439             0.626674   \n",
       "min          0.000000        0.000000        0.000000             1.000000   \n",
       "25%          7.000000      350.000000     3094.000000             2.000000   \n",
       "50%         12.000000      701.000000     6287.000000             2.000000   \n",
       "75%         21.000000     1047.000000     9440.000000             2.000000   \n",
       "max         30.000000     1427.000000    12567.000000             9.000000   \n",
       "\n",
       "                 age  area_percentage  height_percentage  \\\n",
       "count  247382.000000    247382.000000      247382.000000   \n",
       "mean       25.789831         7.842487           5.167842   \n",
       "std        72.616479         4.104327           1.466223   \n",
       "min         0.000000         1.000000           2.000000   \n",
       "25%        10.000000         5.000000           4.000000   \n",
       "50%        15.000000         7.000000           5.000000   \n",
       "75%        30.000000         9.000000           6.000000   \n",
       "max       995.000000        96.000000           8.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "count                 247382.000000                        247382.000000   \n",
       "mean                       0.081586                             0.787098   \n",
       "std                        0.273734                             0.409359   \n",
       "min                        0.000000                             0.000000   \n",
       "25%                        0.000000                             1.000000   \n",
       "50%                        0.000000                             1.000000   \n",
       "75%                        0.000000                             1.000000   \n",
       "max                        1.000000                             1.000000   \n",
       "\n",
       "       has_superstructure_stone_flag  ...  has_secondary_use_hotel  \\\n",
       "count                  247382.000000  ...            247382.000000   \n",
       "mean                        0.035075  ...                 0.026877   \n",
       "std                         0.183971  ...                 0.161726   \n",
       "min                         0.000000  ...                 0.000000   \n",
       "25%                         0.000000  ...                 0.000000   \n",
       "50%                         0.000000  ...                 0.000000   \n",
       "75%                         0.000000  ...                 0.000000   \n",
       "max                         1.000000  ...                 1.000000   \n",
       "\n",
       "       has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "count             247382.000000                  247382.000000   \n",
       "mean                   0.006128                       0.000683   \n",
       "std                    0.078043                       0.026128   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       has_secondary_use_school  has_secondary_use_industry  \\\n",
       "count             247382.000000               247382.000000   \n",
       "mean                   0.000255                    0.001011   \n",
       "std                    0.015956                    0.031774   \n",
       "min                    0.000000                    0.000000   \n",
       "25%                    0.000000                    0.000000   \n",
       "50%                    0.000000                    0.000000   \n",
       "75%                    0.000000                    0.000000   \n",
       "max                    1.000000                    1.000000   \n",
       "\n",
       "       has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "count                  247382.000000                 247382.000000   \n",
       "mean                        0.000141                      0.000101   \n",
       "std                         0.011894                      0.010052   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                         0.000000                      0.000000   \n",
       "50%                         0.000000                      0.000000   \n",
       "75%                         0.000000                      0.000000   \n",
       "max                         1.000000                      1.000000   \n",
       "\n",
       "       has_secondary_use_use_police  has_secondary_use_other   damage_grade  \n",
       "count                 247382.000000            247382.000000  247382.000000  \n",
       "mean                       0.000085                 0.004859       2.247411  \n",
       "std                        0.009213                 0.069536       0.607808  \n",
       "min                        0.000000                 0.000000       1.000000  \n",
       "25%                        0.000000                 0.000000       2.000000  \n",
       "50%                        0.000000                 0.000000       2.000000  \n",
       "75%                        0.000000                 0.000000       3.000000  \n",
       "max                        1.000000                 1.000000       3.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = data.select_dtypes(exclude=['object'])\n",
    "numerical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3567d6b-eff7-4861-ba8f-f1615942fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "def get_right_skewed_columns(df, skew_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns the names of columns that are right-skewed based on the skewness value, excluding binary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The input DataFrame (numerical columns only).\n",
    "    - skew_threshold: The skewness threshold above which a column is considered right-skewed (default is 0.5).\n",
    "    \n",
    "    Returns:\n",
    "    - List of column names that are right-skewed.\n",
    "    \"\"\"\n",
    "    right_skewed_columns = []\n",
    "    \n",
    "    # Iterate through each column in the dataframe\n",
    "    for col in df.columns:\n",
    "        # Check if the column has more than 2 unique values (to avoid binary columns)\n",
    "        if df[col].nunique() > 2:\n",
    "            # Calculate skewness for each column\n",
    "            col_skewness = skew(df[col].dropna())  # Drop NaN values to avoid issues\n",
    "            \n",
    "            # Check if the skewness is above the specified threshold (indicating right-skewness)\n",
    "            if col_skewness > skew_threshold:\n",
    "                right_skewed_columns.append(col)\n",
    "    \n",
    "    return right_skewed_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f2e52e-cd8a-4bef-b7ee-8203b14255a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-skewed columns: ['age', 'area_percentage', 'count_families']\n"
     ]
    }
   ],
   "source": [
    "# # Select numerical columns\n",
    "# numerical_df = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# # Get the right-skewed columns\n",
    "right_skewed_cols = get_right_skewed_columns(numerical_df)\n",
    "\n",
    "print(\"Right-skewed columns:\", right_skewed_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b91e41a-e47d-4d42-a792-9c23b1484604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def apply_log_transformation(df, columns):\n",
    "#     \"\"\"\n",
    "#     Applies log transformation to the specified columns of the DataFrame.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: The input DataFrame.\n",
    "#     - columns: List of column names to apply the log transformation on.\n",
    "    \n",
    "#     Returns:\n",
    "#     - DataFrame with log-transformed columns.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     df_transformed = df.copy()\n",
    "    \n",
    "#     # Apply log transformation to each specified column\n",
    "#     for col in columns:\n",
    "#         # Add a small constant to avoid log(0) and handle any zeros or negatives\n",
    "#         df_transformed[col] = np.log1p([col])\n",
    "    \n",
    "#     return df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80619d75-f6d4-4a9a-9b85-4ae1bea084b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the right-skewed columns (excluding binary columns)\n",
    "#right_skewed_cols = get_right_skewed_columns(numerical_df)\n",
    "#numerical_df = apply_log_transformation(numerical_df, right_skewed_cols)\n",
    "#data[right_skewed_cols] = numerical_df[right_skewed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70b59429-e3a5-4659-a690-451343d1a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pct = np.percentile(data.loc[:, 'age'].fillna(np.mean(data.loc[:, 'age'])), 99)\n",
    "#print(pct)\n",
    "#print(data.shape)\n",
    "#data = data.loc[data.loc[:, 'age'] < pct]\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3911ffc-6f59-459a-919b-a0331862a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(X):\n",
    "    # Apply log1p transformation (log(1 + x)) to avoid issues with zero values\n",
    "    return np.log1p(X)\n",
    "\n",
    "# Create a FunctionTransformer for log transformation\n",
    "log_transformer = FunctionTransformer(log_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58e3fc36-e7c3-4402-94f1-e6ff2ca0a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Custom transformer for the age-based transformation\n",
    "class AgeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, age_column='age'):\n",
    "        self.age_column = age_column\n",
    "        self.percentile_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate the 99th percentile of the 'age' column and store it\n",
    "        self.percentile_ = np.percentile(X[self.age_column].fillna(np.mean(X[self.age_column])), 99)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Add a new 'old' column to indicate if the age exceeds the 99th percentile\n",
    "        X_copy['old'] = np.where(X_copy[self.age_column] >= self.percentile_, 1, 0)\n",
    "        \n",
    "        # Cap the age to 100 where the 'old' column is 1\n",
    "        X_copy.loc[X_copy['old'] == 1, self.age_column] = 100\n",
    "        \n",
    "        return X_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ade25df-1961-4cd1-8288-7d019804fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['damage_grade'])\n",
    "y = data.damage_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8cd2381-4b97-4e93-b311-2de1edc0cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({1: 0, 2: 1, 3: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dba1291f-ff62-40e5-944a-6372b3517406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         2\n",
       "3         1\n",
       "5         1\n",
       "         ..\n",
       "260596    1\n",
       "260597    2\n",
       "260598    2\n",
       "260599    1\n",
       "260600    2\n",
       "Name: damage_grade, Length: 247382, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1c9c93a-0124-4e52-8c6f-1f0d62805c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    140849\n",
       "2     83869\n",
       "0     22664\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f62d6401-05c2-4de0-86e9-9a012300ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.old.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0243ff84-fb14-4ecb-a5cf-953277152a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_df = data.select_dtypes(exclude=['object'])\n",
    "#categorical_df = data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca1d5990-7836-4ff9-9cdf-689ddc2445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in x.columns if  x[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int32', 'int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83ebf2c7-490c-43b9-811f-3c2d149b9f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['land_surface_condition',\n",
       " 'foundation_type',\n",
       " 'roof_type',\n",
       " 'ground_floor_type',\n",
       " 'other_floor_type',\n",
       " 'position',\n",
       " 'plan_configuration',\n",
       " 'legal_ownership_status']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b4ea3f2-1ccf-462f-b581-c21426c40fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(numerical_df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "712173a0-97d3-4475-b68f-a303af290e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler, MinMaxScaler\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5390eb12-6721-40bc-a3e9-f60d922a8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    98747\n",
       "2    58531\n",
       "0    15889\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aca1c3dc-856a-47b7-8258-2657b4318b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    42102\n",
       "2    25338\n",
       "0     6775\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca8125c8-9a46-4a44-b21d-d48ce2f8478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BaseNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dddedeba-4ffe-4e0e-a8b8-ce15fe7864a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.eda_first import summarize_dataframe\n",
    "#summarize_dataframe(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffc2a3a0-b3d2-49f0-90c6-4474abe506e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create numerical transformer\n",
    "\n",
    "numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "#create categorical transformer\n",
    "#categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "#                                            ])\n",
    "\n",
    "base_encoder_columns = ['land_surface_condition', 'geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
    " 'foundation_type',\n",
    " 'roof_type',\n",
    " 'ground_floor_type',\n",
    " 'other_floor_type',\n",
    " 'position',\n",
    " 'plan_configuration',\n",
    " 'legal_ownership_status']\n",
    "\n",
    "base_encoder = Pipeline(steps=[\n",
    "    ('base_encoder', BaseNEncoder(cols=base_encoder_columns, base=5))\n",
    "])\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    ('age_transform', AgeTransformer(age_column='age'))  # Apply age transformation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "69e4328c-afab-40e1-a982-c79bb93326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the transformations using ColumnTransformer\n",
    "#preprocessor = ColumnTransformer(transformers=[\n",
    "#    ('base_name', base_encoder, base_encoder_columns)])  # TargetEncoder for 'town'\n",
    "#    ('num', numerical_transformer, numerical_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee3cdd35-41ef-4fc8-ab5f-3a6a69cf8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated ColumnTransformer with the log transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('base_name', base_encoder, base_encoder_columns),  # BaseNEncoder for categorical columns\n",
    "    ('age_transform', age_transformer, ['age']),  # Custom transformer for the 'age' column\n",
    "    ('num', 'passthrough', numerical_cols),  # Pass numerical columns through without transformation\n",
    "    ('interaction', interaction_transformer, ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id', 'height_percentage', 'area_percentage']),  # Interaction terms\n",
    "    ('log_transform', log_transformer, right_skewed_cols)  # Apply log transformation to specified columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3af85d6-3871-4f19-a54c-1daf5d2a8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# # LightGBM for Multiclass Classification\n",
    "# lgbm = LGBMClassifier(\n",
    "#     n_estimators=800,\n",
    "#     learning_rate=0.2669112505018992,\n",
    "#     max_depth=5,\n",
    "#     random_state=42,\n",
    "#     reg_lambda=1.2259716591605452,  # L2 regularization\n",
    "#     subsample=0.704976942819638,    # Subsample ratio of the training instances\n",
    "#     colsample_bytree=0.9,           # Subsample ratio of columns when constructing each tree\n",
    "#     min_child_weight=4,             # Equivalent of min_data_in_leaf in LightGBM\n",
    "#     reg_alpha=0.14170716330946964,  # L1 regularization term\n",
    "#     objective='multiclass',         # Objective for multiclass classification\n",
    "#     metric='multi_logloss',         # Metric used for multiclass classification\n",
    "#     num_class=3                     # Specify the number of classes in the target\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# rf_pipe = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "#     ('xgboost', lgbm)  # Step 3: Model training\n",
    "# ])\n",
    "\n",
    "# # Preprocessing of training data, fit model \n",
    "# #rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Preprocessing of training data, fit model after upsampling!\n",
    "# rf_pipe.fit(x, y)\n",
    "\n",
    "# # Preprocessing of validation data, get predictions\n",
    "# #rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# #accuracy = accuracy_score(y_test, rf_preds)\n",
    "# #print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# # Detailed classification report\n",
    "# #print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17c7ee6b-4d40-4c75-8673-fb68368f83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.7431112308832446\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58      6775\n",
      "           1       0.74      0.84      0.79     42102\n",
      "           2       0.76      0.64      0.69     25338\n",
      "\n",
      "    accuracy                           0.74     74215\n",
      "   macro avg       0.72      0.66      0.69     74215\n",
      "weighted avg       0.74      0.74      0.74     74215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.2669112505018992,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    reg_lambda=1.2259716591605452,\n",
    "    subsample=0.704976942819638,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=4,\n",
    "    alpha= 0.14170716330946964,    # Added L1 regularization\n",
    "    eval_metric='mlogloss',  # Consider custom loss for ordinal\n",
    "    objective='multi:softmax',  # Using softmax but can tweak for ordinal\n",
    "    num_class=3  # Assuming 3 ordinal classes\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "    ('xgboost', xgb)  # Step 3: Model training\n",
    "])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "#rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of training data, fit model after upsampling!\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d64ed6c4-ad09-4587-9fd8-6430598e11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.799130319287162\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.71     15889\n",
      "           1       0.79      0.89      0.84     98747\n",
      "           2       0.81      0.70      0.75     58531\n",
      "\n",
      "    accuracy                           0.80    173167\n",
      "   macro avg       0.80      0.74      0.77    173167\n",
      "weighted avg       0.80      0.80      0.80    173167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_train, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "daeb6fd1-1fb3-4479-8978-2a38fc3f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/raw/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dafbc507-fb2c-4ad2-8134-70d35d158954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = test_data.building_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "730a579f-3081-41a2-85ae-7ebc758060d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         300051\n",
       "1          99355\n",
       "2         890251\n",
       "3         745817\n",
       "4         421793\n",
       "          ...   \n",
       "86863     310028\n",
       "86864     663567\n",
       "86865    1049160\n",
       "86866     442785\n",
       "86867     501372\n",
       "Name: building_id, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b8315b74-c8b7-46a7-8bf9-e92323217a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        2\n",
       "        ..\n",
       "86863    1\n",
       "86864    1\n",
       "86865    1\n",
       "86866    1\n",
       "86867    1\n",
       "Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_preds = rf_pipe.predict(test_data)\n",
    "rf_preds = pd.Series(rf_preds)\n",
    "rf_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "80bebbfa-d40f-41b9-9103-a3dfca239303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([X_test_final, rf_preds], axis=1)\n",
    "df_concatenated\n",
    "df_concatenated = df_concatenated.rename(columns={0: 'damage_grade'})\n",
    "df_concatenated\n",
    "df_concatenated['damage_grade'] = df_concatenated['damage_grade'].replace({0: 1, 1: 2, 2: 3})\n",
    "df_concatenated.to_csv('../data/processed/submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28226e9-3c26-44cb-beda-9c50233aadc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
